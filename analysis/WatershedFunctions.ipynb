{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete image processing\n",
    "*Input*: directory locations with images (.tif)\n",
    "\n",
    "*Output*: data structure with particle positions in real space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.optimize as optimization\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import fnmatch\n",
    "import json\n",
    "\n",
    "# !jupyter nbconvert --to script Images2positions.ipynb\n",
    "print('Loading modules completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Writing Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Image handling #\n",
    "##################\n",
    "\n",
    "# Read the image from the given path, open it and crop it.\n",
    "def readcropimage(path,bitdepth=8):\n",
    "    #Read image\n",
    "    if bitdepth==8:\n",
    "        image = cv2.imread(path,cv2.CV_8UC1)\n",
    "        image = image*16\n",
    "    elif bitdepth==16:\n",
    "        image = cv2.imread(path,cv2.CV_16UC1)\n",
    "        \n",
    "    # Crop image\n",
    "    image = image[bounds[0]:-1-bounds[1],bounds[2]:-1-bounds[3]]\n",
    "    return image\n",
    "\n",
    "\n",
    "# Threshold the input\n",
    "def thresholdimage(image,bordered=True):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    _, threshold = cv2.threshold(image,thresholdvalue,255,cv2.THRESH_BINARY)\n",
    "    threshold = cv2.morphologyEx(threshold,cv2.MORPH_OPEN,kernel,iterations=1)\n",
    "\n",
    "    # Invert the image\n",
    "    threshold = ~np.uint8(threshold)\n",
    "    \n",
    "    # Add a border of zeros\n",
    "    if bordered:\n",
    "        threshold = np.pad(threshold, pad_width=1, mode='constant', constant_values=0)\n",
    "        \n",
    "    return threshold\n",
    "\n",
    "\n",
    "# Background\n",
    "def background(image,iters=1):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    background = cv2.dilate(image,kernel,iterations=iters)\n",
    "    return background\n",
    "\n",
    "\n",
    "# Foreground\n",
    "def foreground(image,dttype='L1'):\n",
    "    # Calculate the distance transform\n",
    "    if dttype=='L1': # as (|x1-x2|+|y1-y2|)\n",
    "        disttrans = cv2.distanceTransform(image,cv2.DIST_L1,0)\n",
    "    elif dttype=='C': # as max(|x1-x2|,|y1-y2|)\n",
    "        disttrans = cv2.distanceTransform(image,cv2.DIST_C,0)\n",
    "    \n",
    "    # disttrans is used for comparisons and obtaining values of the distance transform\n",
    "    # centers is defined as disttrans, but in the coming loops sections are altered and put to zero.\n",
    "    centers = disttrans*1    #*1 otherwise if centers is adjusted, so is disttrans\n",
    "\n",
    "    # Loop over the values in distancetransform, starting with the highest value\n",
    "    for k in range(int(np.max(disttrans)),0,-1):\n",
    "        # markers contains the patches of same value in the distance transform\n",
    "        q = np.where(disttrans==k,1,0)\n",
    "        q = np.uint8(q)\n",
    "        _, markers = cv2.connectedComponents(q)\n",
    "\n",
    "        # Loop over the patches\n",
    "        for qi in range(1,np.max(markers)+1,1):\n",
    "            px,py = np.where(markers == qi)    \n",
    "\n",
    "            # Loop over the pixels in the patch and check if there are any higher neighbours. If yes, then it is not a local maximum\n",
    "            for i in range(0,np.size(px),1):\n",
    "\n",
    "                # For all neighbours of the pixel, check if there are any values higher than the pixel value (k)\n",
    "                neighbours = disttrans[px[i]-1:px[i]+2,py[i]-1:py[i]+2]\n",
    "                if np.any(neighbours>k):\n",
    "                    centers[px,py] = 0\n",
    "#                     break\n",
    "\n",
    "    foreground = np.uint8(centers>0)\n",
    "    \n",
    "#     foreground = cv2.dilate(foreground,np.ones((3,3),np.uint8),iterations=1)\n",
    "    return foreground\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Object recognition #\n",
    "######################\n",
    "\n",
    "def findlines(image, centerpx = centerpx, binarize=False, gaussianfilter=True):\n",
    "    # Extract part of the image, remove center for better statistics\n",
    "    linearea = np.concatenate((image[0:centerpx[0],:],image[centerpx[1]:,:]))\n",
    "    \n",
    "    # Threshold the extracted part of the image to obtain the lines\n",
    "    threshold = cv2.adaptiveThreshold(linearea,1,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,10)\n",
    "#     threshold = cv2.adaptiveThreshold(linearea,1,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,25,10)  \n",
    "    \n",
    "    # Remove some additional noise caused by shadows\n",
    "    threshold = cv2.morphologyEx(threshold,cv2.MORPH_CLOSE,np.ones((3,3),np.uint8),iterations=1)\n",
    "    threshold = ~np.uint8(threshold)\n",
    "    \n",
    "    # Average and normalize to obtain 1D data (Since particles may overlap the lines)\n",
    "    averages = (np.average(threshold,axis=0)-np.min(threshold))/(np.max(threshold)-np.min(threshold))\n",
    "    \n",
    "    # Threshold the 1D data to obtain binary information\n",
    "    if binarize == True:\n",
    "         averages = cv2.threshold(averages,0.1,1,cv2.THRESH_BINARY)[1]\n",
    "       \n",
    "    if gaussianfilter == True:\n",
    "        averages = ndimage.gaussian_filter1d(averages,sigma=1)\n",
    "        \n",
    "    # Fit lines with a fixed minimum separation distance    \n",
    "    lines, _ = find_peaks(averages, distance=linespacingpx)\n",
    "    \n",
    "    return lines\n",
    "\n",
    "\n",
    "def findparticles(image):\n",
    "    # Threshold the image\n",
    "    threshold = thresholdimage(image,bordered=True)\n",
    "    \n",
    "    # Compute element of picture that are surely background or foreground\n",
    "    sure_background = background(threshold)\n",
    "    sure_foreground = foreground(threshold)\n",
    "    \n",
    "    _, thresholdcomponents = cv2.connectedComponents(threshold)\n",
    "       \n",
    "    # Calculate the unknown area between foreground and background\n",
    "    unknown = cv2.subtract(sure_background,sure_foreground)\n",
    "\n",
    "    # Setup the markers based on the foreground\n",
    "    _, markers = cv2.connectedComponents(sure_foreground)\n",
    "    markers += 1\n",
    "    markers[unknown==255] = 0\n",
    "\n",
    "    # Setup the image to be used in the watershed transform\n",
    "    imagewatershed = cv2.cvtColor(np.uint8(threshold),cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Do the watershed transform\n",
    "    markers = cv2.watershed(imagewatershed,markers)\n",
    "    \n",
    "    # Remove the border that was added during the thresholding\n",
    "    markers_noborder = markers[1:-1,1:-1]\n",
    "        \n",
    "    return markers_noborder\n",
    "\n",
    "\n",
    "def removeparticles(image,markers,dilate=True,dilatesize=11):\n",
    "    # Create mask to use in filtering of particles\n",
    "    mask = np.where(markers>1,1,0)\n",
    "    \n",
    "    # Dilate the mask such that shadows can be removed as well\n",
    "    if dilate:\n",
    "        dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(dilatesize,dilatesize))\n",
    "        mask = cv2.dilate(np.uint8(mask),dilate_kernel,iterations=1)\n",
    "    \n",
    "    image_noparticles = np.where(mask==1,np.mean(image),image)\n",
    "    \n",
    "    return image_noparticles\n",
    " \n",
    "def particlesfilter(image,markers):\n",
    "    #Number of markers (= detected particles+2)\n",
    "    N = np.max(markers)\n",
    "    positions = np.empty((N-1,2),dtype=float)\n",
    "    \n",
    "    # Size distribution of markers\n",
    "    sizes = [np.sum(np.where(markers==j,1,0)) for j in range(2,N,1)]\n",
    "    meansize = np.mean(sizes)\n",
    "\n",
    "    # Maximum number of pixels to count as 1 particle\n",
    "    maxpx = meansize*1.7\n",
    "    \n",
    "    # Minimum number of pixels required to count as particle\n",
    "    minpx = meansize*0.5\n",
    "    \n",
    "    # New marker set that is appended\n",
    "    newmarkersset = np.zeros(np.shape(markers),dtype=int)\n",
    "    \n",
    "    imagefiltered = np.zeros(np.shape(image),dtype=int)\n",
    "#     pointsinmarkers = [[],[]]\n",
    "    \n",
    "    # Loop over the particles, 0 is nothing, 1 is background, so start from 2\n",
    "    for i in range(2,N+1,1):\n",
    "        # Create mask to use in filtering of particles\n",
    "        mask = np.where(markers==i,1,0)\n",
    "        \n",
    "        # If particle < minpx skip it, if >maxpx split it\n",
    "        if minpx <= np.sum(mask) <= maxpx:\n",
    "#             print(np.max(newmarkersset))\n",
    "            newmarkersset[mask!=0] += np.max(newmarkersset)+1\n",
    "        elif np.sum(mask) > maxpx:\n",
    "            if verbose: print('Particle',i,'too large:',np.sum(mask),'px. Will be split in probably',int(round(np.sum(mask)/meansize)),'particles.')\n",
    "            \n",
    "            particle = np.where(mask==1,image,0) \n",
    "            \n",
    "            # Coordinates of pixels in (blob of) particles\n",
    "            coordpx = np.argwhere(particle!=0)\n",
    "            px = coordpx[:,0]\n",
    "            py = coordpx[:,1]\n",
    "            \n",
    "            imagefiltered[px,py] = 1\n",
    "#             pointsinmarkers = np.append(pointsinmarkers,[px,py],axis=1)\n",
    "            \n",
    "            weights = particle[px,py]\n",
    "            \n",
    "            center = [np.average(py,weights=weights),np.average(px,weights=weights)]\n",
    "            centerintx = int(center[1])\n",
    "            centerinty = int(center[0])\n",
    "            \n",
    "            pxx = np.linspace(centerintx-1,centerintx+1,3,dtype=int)\n",
    "            pyy = np.linspace(centerinty-1,centerinty+1,3,dtype=int)\n",
    "            Px, Py = np.meshgrid(pxx,pyy)\n",
    "#             image[Px,Py] = np.max(image)\n",
    "            \n",
    "    return imagefiltered #image, image2\n",
    "    \n",
    "    \n",
    "def particlepositions(image,markers,weightedaverage=False):\n",
    "    #Number of markers (=particles+2)\n",
    "    N = np.max(markers)\n",
    "    positions = np.empty((N-1,2),dtype=float)\n",
    "    \n",
    "    # Size distribution of markers\n",
    "    sizes = [np.sum(np.where(markers==j,1,0)) for j in range(2,N,1)]\n",
    "    meansize = np.mean(sizes)\n",
    "    \n",
    "    # Maximum number of pixels to count as 1 particle\n",
    "    maxpx = meansize*1.7\n",
    "    \n",
    "    # Minimum number of pixels required to count as particle\n",
    "    minpx = 10\n",
    "\n",
    "    # Loop over the particles, 0 is nothing, 1 is background, so start from 2\n",
    "    for i in range(2,N+1,1):\n",
    "        # Create mask to use in filtering of particles\n",
    "        mask = np.where(markers==i,1,0)\n",
    "        \n",
    "        particle = np.where(mask==1,image,0) \n",
    "            \n",
    "        # Coordinates of pixels in particle\n",
    "        coordpx = np.argwhere(particle!=0)\n",
    "        px = coordpx[:,0]\n",
    "        py = coordpx[:,1]\n",
    "\n",
    "        # Weighted average\n",
    "        if weightedaverage:\n",
    "            weights = particle[px,py]\n",
    "        # Normal average\n",
    "        else:\n",
    "            weights = np.ones(np.size(px))\n",
    "\n",
    "        center = [np.average(py,weights=weights),np.average(px,weights=weights)]\n",
    "               \n",
    "        positions[i-2,:] = center           \n",
    "    \n",
    "    return positions\n",
    "\n",
    "def correctmarkers(image,markers):\n",
    "    markerscorrection = particlesfilter(image,markers)\n",
    "\n",
    "    threshold = thresholdimage(image,bordered=False)\n",
    "    _, thresholdcomponents = cv2.connectedComponents(threshold)\n",
    "\n",
    "    imagecorrected = image*1\n",
    "\n",
    "    for i in range(1,np.max(thresholdcomponents),1):\n",
    "        a = np.where(thresholdcomponents==i,1,0)    \n",
    "    #     b = a*pointsinmarker\n",
    "        b = a*markerscorrection\n",
    "        if np.sum(a*b)>0:\n",
    "            c = foreground(np.uint8(a))\n",
    "            d = cv2.dilate(np.uint8(c*markerscorrection),np.ones((3,3),np.uint8),iterations=1)\n",
    "            imagecorrected[d==1] = np.max(imagecorrected)\n",
    "    markerscorrected = findparticles(imagecorrected)\n",
    "    \n",
    "    return imagecorrected, markerscorrected\n",
    "\n",
    "############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
